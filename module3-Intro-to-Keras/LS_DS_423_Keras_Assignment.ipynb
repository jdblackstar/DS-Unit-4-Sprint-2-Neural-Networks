{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_433_Keras_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Neural Network Framework (Keras)\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8NLTAR87uYJ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6b081a9c-17ef-4318-d559-6ece9379b7da"
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s8jiecMt8nS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef527acf-395e-4c4a-e390-a0c48a1660a3"
      },
      "source": [
        "type(boston_housing)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "module"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAW0qRjJt_AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjAOlI2EuMWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccf7678d-b9d7-4efc-84ee-37d7af90ce79"
      },
      "source": [
        "X_train_scaled.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVKWTyMiuPdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "n_features = 13\n",
        "\n",
        "model.add(Dense(13, input_dim=n_features))\n",
        "model.add(Dense(20, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"linear\"))\n",
        "\n",
        "model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mae\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Q2P8Z6upS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cbbfba24-a5d2-42a5-ac22-ad4a55402af5"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "nn_callback = EarlyStopping(monitor=\"mae\", patience=5)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=9999, validation_data=(X_test_scaled, y_test), callbacks=[nn_callback])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9999\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 22.0734 - mae: 22.0734 - val_loss: 22.4008 - val_mae: 22.4008\n",
            "Epoch 2/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 21.4823 - mae: 21.4823 - val_loss: 21.8139 - val_mae: 21.8139\n",
            "Epoch 3/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 20.8724 - mae: 20.8724 - val_loss: 21.1369 - val_mae: 21.1369\n",
            "Epoch 4/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 20.1376 - mae: 20.1376 - val_loss: 20.2793 - val_mae: 20.2793\n",
            "Epoch 5/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 19.1936 - mae: 19.1936 - val_loss: 19.1852 - val_mae: 19.1852\n",
            "Epoch 6/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 17.9995 - mae: 17.9995 - val_loss: 17.8254 - val_mae: 17.8254\n",
            "Epoch 7/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 16.5241 - mae: 16.5241 - val_loss: 16.2332 - val_mae: 16.2332\n",
            "Epoch 8/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 14.7520 - mae: 14.7520 - val_loss: 14.5036 - val_mae: 14.5036\n",
            "Epoch 9/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 12.8746 - mae: 12.8746 - val_loss: 12.7753 - val_mae: 12.7753\n",
            "Epoch 10/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 11.1336 - mae: 11.1336 - val_loss: 11.1524 - val_mae: 11.1524\n",
            "Epoch 11/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 9.7436 - mae: 9.7436 - val_loss: 9.7769 - val_mae: 9.7769\n",
            "Epoch 12/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 8.8010 - mae: 8.8010 - val_loss: 8.9798 - val_mae: 8.9798\n",
            "Epoch 13/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 8.2024 - mae: 8.2024 - val_loss: 8.5181 - val_mae: 8.5181\n",
            "Epoch 14/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.8316 - mae: 7.8316 - val_loss: 8.1968 - val_mae: 8.1968\n",
            "Epoch 15/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.5566 - mae: 7.5566 - val_loss: 7.9279 - val_mae: 7.9279\n",
            "Epoch 16/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.3053 - mae: 7.3053 - val_loss: 7.6840 - val_mae: 7.6840\n",
            "Epoch 17/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.0620 - mae: 7.0620 - val_loss: 7.4614 - val_mae: 7.4614\n",
            "Epoch 18/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.8280 - mae: 6.8280 - val_loss: 7.2446 - val_mae: 7.2446\n",
            "Epoch 19/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.5839 - mae: 6.5839 - val_loss: 7.0079 - val_mae: 7.0079\n",
            "Epoch 20/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.3649 - mae: 6.3649 - val_loss: 6.7941 - val_mae: 6.7941\n",
            "Epoch 21/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 6.1563 - mae: 6.1563 - val_loss: 6.6319 - val_mae: 6.6319\n",
            "Epoch 22/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.9450 - mae: 5.9450 - val_loss: 6.4267 - val_mae: 6.4267\n",
            "Epoch 23/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.7522 - mae: 5.7522 - val_loss: 6.2443 - val_mae: 6.2443\n",
            "Epoch 24/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.5775 - mae: 5.5775 - val_loss: 6.0797 - val_mae: 6.0797\n",
            "Epoch 25/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.4128 - mae: 5.4128 - val_loss: 5.9283 - val_mae: 5.9283\n",
            "Epoch 26/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.2813 - mae: 5.2813 - val_loss: 5.7610 - val_mae: 5.7610\n",
            "Epoch 27/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.1608 - mae: 5.1608 - val_loss: 5.6426 - val_mae: 5.6426\n",
            "Epoch 28/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.0655 - mae: 5.0655 - val_loss: 5.5458 - val_mae: 5.5458\n",
            "Epoch 29/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.9781 - mae: 4.9781 - val_loss: 5.4711 - val_mae: 5.4711\n",
            "Epoch 30/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.9278 - mae: 4.9278 - val_loss: 5.4004 - val_mae: 5.4004\n",
            "Epoch 31/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.8736 - mae: 4.8736 - val_loss: 5.3418 - val_mae: 5.3418\n",
            "Epoch 32/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.8449 - mae: 4.8449 - val_loss: 5.2803 - val_mae: 5.2803\n",
            "Epoch 33/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7999 - mae: 4.7999 - val_loss: 5.2377 - val_mae: 5.2377\n",
            "Epoch 34/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7781 - mae: 4.7781 - val_loss: 5.1980 - val_mae: 5.1980\n",
            "Epoch 35/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.7530 - mae: 4.7530 - val_loss: 5.1486 - val_mae: 5.1486\n",
            "Epoch 36/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.7318 - mae: 4.7318 - val_loss: 5.1231 - val_mae: 5.1231\n",
            "Epoch 37/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6936 - mae: 4.6936 - val_loss: 5.0733 - val_mae: 5.0733\n",
            "Epoch 38/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6922 - mae: 4.6922 - val_loss: 5.0384 - val_mae: 5.0384\n",
            "Epoch 39/9999\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.6509 - mae: 4.6509 - val_loss: 5.0035 - val_mae: 5.0035\n",
            "Epoch 40/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6165 - mae: 4.6165 - val_loss: 4.9913 - val_mae: 4.9913\n",
            "Epoch 41/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5933 - mae: 4.5933 - val_loss: 4.9588 - val_mae: 4.9588\n",
            "Epoch 42/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5782 - mae: 4.5782 - val_loss: 4.9192 - val_mae: 4.9192\n",
            "Epoch 43/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.5410 - mae: 4.5410 - val_loss: 4.9122 - val_mae: 4.9122\n",
            "Epoch 44/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5250 - mae: 4.5250 - val_loss: 4.8713 - val_mae: 4.8713\n",
            "Epoch 45/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.4928 - mae: 4.4928 - val_loss: 4.8355 - val_mae: 4.8355\n",
            "Epoch 46/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4762 - mae: 4.4762 - val_loss: 4.8019 - val_mae: 4.8019\n",
            "Epoch 47/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4440 - mae: 4.4440 - val_loss: 4.7815 - val_mae: 4.7815\n",
            "Epoch 48/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.4240 - mae: 4.4240 - val_loss: 4.7514 - val_mae: 4.7514\n",
            "Epoch 49/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.4138 - mae: 4.4138 - val_loss: 4.7515 - val_mae: 4.7515\n",
            "Epoch 50/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3736 - mae: 4.3736 - val_loss: 4.6739 - val_mae: 4.6739\n",
            "Epoch 51/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3491 - mae: 4.3491 - val_loss: 4.6719 - val_mae: 4.6719\n",
            "Epoch 52/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3243 - mae: 4.3243 - val_loss: 4.6404 - val_mae: 4.6404\n",
            "Epoch 53/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3002 - mae: 4.3002 - val_loss: 4.5827 - val_mae: 4.5827\n",
            "Epoch 54/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2711 - mae: 4.2711 - val_loss: 4.5670 - val_mae: 4.5670\n",
            "Epoch 55/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.2530 - mae: 4.2530 - val_loss: 4.5275 - val_mae: 4.5275\n",
            "Epoch 56/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2241 - mae: 4.2241 - val_loss: 4.5115 - val_mae: 4.5115\n",
            "Epoch 57/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.2036 - mae: 4.2036 - val_loss: 4.4741 - val_mae: 4.4741\n",
            "Epoch 58/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1774 - mae: 4.1774 - val_loss: 4.4602 - val_mae: 4.4602\n",
            "Epoch 59/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.1616 - mae: 4.1616 - val_loss: 4.4125 - val_mae: 4.4125\n",
            "Epoch 60/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.1310 - mae: 4.1310 - val_loss: 4.3887 - val_mae: 4.3887\n",
            "Epoch 61/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1092 - mae: 4.1092 - val_loss: 4.3563 - val_mae: 4.3563\n",
            "Epoch 62/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0940 - mae: 4.0940 - val_loss: 4.3164 - val_mae: 4.3164\n",
            "Epoch 63/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0847 - mae: 4.0847 - val_loss: 4.2923 - val_mae: 4.2923\n",
            "Epoch 64/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0456 - mae: 4.0456 - val_loss: 4.2539 - val_mae: 4.2539\n",
            "Epoch 65/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.0301 - mae: 4.0301 - val_loss: 4.2225 - val_mae: 4.2225\n",
            "Epoch 66/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.0041 - mae: 4.0041 - val_loss: 4.2085 - val_mae: 4.2085\n",
            "Epoch 67/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.9785 - mae: 3.9785 - val_loss: 4.1471 - val_mae: 4.1471\n",
            "Epoch 68/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.9554 - mae: 3.9554 - val_loss: 4.1282 - val_mae: 4.1282\n",
            "Epoch 69/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.9365 - mae: 3.9365 - val_loss: 4.0927 - val_mae: 4.0927\n",
            "Epoch 70/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.9253 - mae: 3.9253 - val_loss: 4.0309 - val_mae: 4.0309\n",
            "Epoch 71/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.8978 - mae: 3.8978 - val_loss: 4.0548 - val_mae: 4.0548\n",
            "Epoch 72/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.8831 - mae: 3.8831 - val_loss: 4.0101 - val_mae: 4.0101\n",
            "Epoch 73/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.8745 - mae: 3.8745 - val_loss: 3.9474 - val_mae: 3.9474\n",
            "Epoch 74/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.8402 - mae: 3.8402 - val_loss: 3.9376 - val_mae: 3.9376\n",
            "Epoch 75/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.8283 - mae: 3.8283 - val_loss: 3.9055 - val_mae: 3.9055\n",
            "Epoch 76/9999\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 3.8066 - mae: 3.8066 - val_loss: 3.8930 - val_mae: 3.8930\n",
            "Epoch 77/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.7836 - mae: 3.7836 - val_loss: 3.8582 - val_mae: 3.8582\n",
            "Epoch 78/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.7660 - mae: 3.7660 - val_loss: 3.8049 - val_mae: 3.8049\n",
            "Epoch 79/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.7409 - mae: 3.7409 - val_loss: 3.8057 - val_mae: 3.8057\n",
            "Epoch 80/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.7304 - mae: 3.7304 - val_loss: 3.7946 - val_mae: 3.7946\n",
            "Epoch 81/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.7128 - mae: 3.7128 - val_loss: 3.7247 - val_mae: 3.7247\n",
            "Epoch 82/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.6946 - mae: 3.6946 - val_loss: 3.7144 - val_mae: 3.7144\n",
            "Epoch 83/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.6637 - mae: 3.6637 - val_loss: 3.6937 - val_mae: 3.6937\n",
            "Epoch 84/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.6518 - mae: 3.6518 - val_loss: 3.6634 - val_mae: 3.6634\n",
            "Epoch 85/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.6222 - mae: 3.6222 - val_loss: 3.6514 - val_mae: 3.6514\n",
            "Epoch 86/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.6164 - mae: 3.6164 - val_loss: 3.6304 - val_mae: 3.6304\n",
            "Epoch 87/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.5792 - mae: 3.5792 - val_loss: 3.6119 - val_mae: 3.6119\n",
            "Epoch 88/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.5683 - mae: 3.5683 - val_loss: 3.5890 - val_mae: 3.5890\n",
            "Epoch 89/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.5463 - mae: 3.5463 - val_loss: 3.5600 - val_mae: 3.5600\n",
            "Epoch 90/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.5393 - mae: 3.5393 - val_loss: 3.5459 - val_mae: 3.5459\n",
            "Epoch 91/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.5221 - mae: 3.5221 - val_loss: 3.5322 - val_mae: 3.5322\n",
            "Epoch 92/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.5161 - mae: 3.5161 - val_loss: 3.5079 - val_mae: 3.5079\n",
            "Epoch 93/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.4842 - mae: 3.4842 - val_loss: 3.5159 - val_mae: 3.5159\n",
            "Epoch 94/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.4547 - mae: 3.4547 - val_loss: 3.4761 - val_mae: 3.4761\n",
            "Epoch 95/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.4366 - mae: 3.4366 - val_loss: 3.4665 - val_mae: 3.4665\n",
            "Epoch 96/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.4175 - mae: 3.4175 - val_loss: 3.4969 - val_mae: 3.4969\n",
            "Epoch 97/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.4078 - mae: 3.4078 - val_loss: 3.4368 - val_mae: 3.4368\n",
            "Epoch 98/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.3981 - mae: 3.3981 - val_loss: 3.4393 - val_mae: 3.4393\n",
            "Epoch 99/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.3822 - mae: 3.3822 - val_loss: 3.4228 - val_mae: 3.4228\n",
            "Epoch 100/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.3743 - mae: 3.3743 - val_loss: 3.4049 - val_mae: 3.4049\n",
            "Epoch 101/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.3906 - mae: 3.3906 - val_loss: 3.3951 - val_mae: 3.3951\n",
            "Epoch 102/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.3549 - mae: 3.3549 - val_loss: 3.3935 - val_mae: 3.3935\n",
            "Epoch 103/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.3398 - mae: 3.3398 - val_loss: 3.3964 - val_mae: 3.3964\n",
            "Epoch 104/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.3292 - mae: 3.3292 - val_loss: 3.3708 - val_mae: 3.3708\n",
            "Epoch 105/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.3129 - mae: 3.3129 - val_loss: 3.3577 - val_mae: 3.3577\n",
            "Epoch 106/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.3170 - mae: 3.3170 - val_loss: 3.3454 - val_mae: 3.3454\n",
            "Epoch 107/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.3205 - mae: 3.3205 - val_loss: 3.3470 - val_mae: 3.3470\n",
            "Epoch 108/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2981 - mae: 3.2981 - val_loss: 3.3307 - val_mae: 3.3307\n",
            "Epoch 109/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2852 - mae: 3.2852 - val_loss: 3.3077 - val_mae: 3.3077\n",
            "Epoch 110/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2789 - mae: 3.2789 - val_loss: 3.3137 - val_mae: 3.3137\n",
            "Epoch 111/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2694 - mae: 3.2694 - val_loss: 3.2967 - val_mae: 3.2967\n",
            "Epoch 112/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2573 - mae: 3.2573 - val_loss: 3.2963 - val_mae: 3.2963\n",
            "Epoch 113/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.2616 - mae: 3.2616 - val_loss: 3.2766 - val_mae: 3.2766\n",
            "Epoch 114/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2499 - mae: 3.2499 - val_loss: 3.2685 - val_mae: 3.2685\n",
            "Epoch 115/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2403 - mae: 3.2403 - val_loss: 3.2580 - val_mae: 3.2580\n",
            "Epoch 116/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.2356 - mae: 3.2356 - val_loss: 3.2499 - val_mae: 3.2499\n",
            "Epoch 117/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2433 - mae: 3.2433 - val_loss: 3.2361 - val_mae: 3.2361\n",
            "Epoch 118/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2564 - mae: 3.2564 - val_loss: 3.2246 - val_mae: 3.2246\n",
            "Epoch 119/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.1973 - mae: 3.1973 - val_loss: 3.2625 - val_mae: 3.2625\n",
            "Epoch 120/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2239 - mae: 3.2239 - val_loss: 3.2001 - val_mae: 3.2001\n",
            "Epoch 121/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2378 - mae: 3.2378 - val_loss: 3.2027 - val_mae: 3.2027\n",
            "Epoch 122/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.2076 - mae: 3.2076 - val_loss: 3.1787 - val_mae: 3.1787\n",
            "Epoch 123/9999\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.2079 - mae: 3.2079 - val_loss: 3.1803 - val_mae: 3.1803\n",
            "Epoch 124/9999\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.1986 - mae: 3.1986 - val_loss: 3.1709 - val_mae: 3.1709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f47febb6710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyA6aiSRvDSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test_scaled)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg0A7XwuvHwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bf1a7a7f-fdad-468a-f77e-90cb5fbba709"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import math\n",
        "\n",
        "print(\"RMSE:\", math.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"R2:\", r2_score(y_test, y_pred))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 4.59069353367891\n",
            "MAE: 3.170899804433187\n",
            "R2: 0.7468345409913544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SfcFnOONyuNm"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szi6-IpuzaH1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "f2e0c474-10e8-41bc-b994-ff75a9a299ab"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7OWNK1PvVac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_scaled = x_train/255\n",
        "x_test_scaled = x_test/255"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfNTRgyHvXR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "870ff296-e5de-44d5-902c-cf3002dec0d6"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-lfKiU4vYiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "stop = EarlyStopping(monitor='val_accuracy', patience=8)\n",
        "\n",
        "n_features = 784\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(200, input_dim=n_features))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiXVKWTTvaQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "d634ed53-8924-4182-ac46-56e02d7168ff"
      },
      "source": [
        "model.fit(x_train_scaled, y_train, epochs=9999, validation_data=(x_test_scaled, y_test), callbacks=[stop])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4957 - accuracy: 0.8225 - val_loss: 0.4586 - val_accuracy: 0.8327\n",
            "Epoch 2/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3810 - accuracy: 0.8616 - val_loss: 0.4657 - val_accuracy: 0.8414\n",
            "Epoch 3/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3524 - accuracy: 0.8703 - val_loss: 0.4175 - val_accuracy: 0.8530\n",
            "Epoch 4/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3290 - accuracy: 0.8788 - val_loss: 0.3907 - val_accuracy: 0.8601\n",
            "Epoch 5/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3140 - accuracy: 0.8833 - val_loss: 0.4026 - val_accuracy: 0.8607\n",
            "Epoch 6/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3033 - accuracy: 0.8876 - val_loss: 0.3652 - val_accuracy: 0.8749\n",
            "Epoch 7/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2909 - accuracy: 0.8920 - val_loss: 0.4041 - val_accuracy: 0.8635\n",
            "Epoch 8/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2848 - accuracy: 0.8942 - val_loss: 0.3680 - val_accuracy: 0.8769\n",
            "Epoch 9/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2741 - accuracy: 0.8976 - val_loss: 0.3506 - val_accuracy: 0.8786\n",
            "Epoch 10/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2672 - accuracy: 0.9001 - val_loss: 0.3600 - val_accuracy: 0.8710\n",
            "Epoch 11/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2613 - accuracy: 0.9023 - val_loss: 0.4190 - val_accuracy: 0.8614\n",
            "Epoch 12/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2588 - accuracy: 0.9035 - val_loss: 0.3747 - val_accuracy: 0.8663\n",
            "Epoch 13/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2506 - accuracy: 0.9057 - val_loss: 0.4103 - val_accuracy: 0.8648\n",
            "Epoch 14/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2472 - accuracy: 0.9067 - val_loss: 0.3418 - val_accuracy: 0.8827\n",
            "Epoch 15/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2434 - accuracy: 0.9091 - val_loss: 0.3657 - val_accuracy: 0.8746\n",
            "Epoch 16/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2379 - accuracy: 0.9105 - val_loss: 0.3728 - val_accuracy: 0.8767\n",
            "Epoch 17/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2312 - accuracy: 0.9126 - val_loss: 0.3806 - val_accuracy: 0.8777\n",
            "Epoch 18/9999\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2312 - accuracy: 0.9129 - val_loss: 0.4052 - val_accuracy: 0.8760\n",
            "Epoch 19/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2260 - accuracy: 0.9154 - val_loss: 0.3902 - val_accuracy: 0.8748\n",
            "Epoch 20/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2236 - accuracy: 0.9156 - val_loss: 0.4133 - val_accuracy: 0.8709\n",
            "Epoch 21/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2182 - accuracy: 0.9171 - val_loss: 0.4321 - val_accuracy: 0.8714\n",
            "Epoch 22/9999\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2167 - accuracy: 0.9186 - val_loss: 0.4018 - val_accuracy: 0.8736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f47fa26f048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLEFBIOkvb9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "18aa2d55-6c9c-4f4c-f74e-723272148e91"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_per_epoch = model.history.history['val_accuracy']\n",
        "plt.plot(range(len(loss_per_epoch)),loss_per_epoch);"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8l9G4d3vdlT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7906bd83-bfff-4f1a-b66d-37ff60f8127e"
      },
      "source": [
        "loss_per_epoch = model.history.history['loss']\n",
        "plt.plot(range(len(loss_per_epoch)),loss_per_epoch);"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAPnNyFHvfs8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "750677fd-ebab-47c5-9b6b-72bd5ad08ae9"
      },
      "source": [
        "x_train_scaled.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zv_3xNMjzdLI"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef0JanftuOPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}